{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leehyunjoo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[10])\n",
    "# 각 샘플에 쓰인 단어의 개수가 다르고, 이 단어들을 정수인덱스를 바꾼게 샘플에 리스트 형태로 들어가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  3, ..., 25,  3, 25], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10] # 이걸 통해서 어떤 토픽인지 라벨을 달 수 있다고..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "영화 리뷰 분류 문제에서는 긍정적(1), 부정적(0)으로 출력 클래스의 개수가 2개였다.\n",
    "하지만 뉴스 토픽 분류 분제는 뉴스를 46개의 토픽으로 분류하므로, 출력 크래스가 16개이다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 *병목* 이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:\n",
    "\n",
    "( *병목(bottleneck) 현상은 전체 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한을 받는 현상을 말한다. \"병목\"이라는 용어는 물이 병 밖으로 빠져나갈 때 병의 몸통보다 병의 목부분의 내부 지름이 좁아서 물이 상대적으로 천천히 쏟아지는 것에 비유한 것이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 164us/step - loss: 2.5819 - accuracy: 0.5341 - val_loss: 1.7103 - val_accuracy: 0.6380\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 1.3976 - accuracy: 0.7055 - val_loss: 1.3069 - val_accuracy: 0.7100\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 1.0349 - accuracy: 0.7772 - val_loss: 1.1377 - val_accuracy: 0.7470\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.8126 - accuracy: 0.8285 - val_loss: 1.0178 - val_accuracy: 0.7930\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.6459 - accuracy: 0.8664 - val_loss: 0.9620 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.5198 - accuracy: 0.8906 - val_loss: 0.9241 - val_accuracy: 0.8070\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.4227 - accuracy: 0.9132 - val_loss: 0.8906 - val_accuracy: 0.8190\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.3456 - accuracy: 0.9266 - val_loss: 0.8961 - val_accuracy: 0.8110\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.2857 - accuracy: 0.9366 - val_loss: 0.8815 - val_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.2459 - accuracy: 0.9434 - val_loss: 0.8918 - val_accuracy: 0.8170\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.2106 - accuracy: 0.9496 - val_loss: 0.9082 - val_accuracy: 0.8170\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.1846 - accuracy: 0.9505 - val_loss: 0.9184 - val_accuracy: 0.8200\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.1628 - accuracy: 0.9539 - val_loss: 0.9802 - val_accuracy: 0.8020\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.1532 - accuracy: 0.9536 - val_loss: 0.9673 - val_accuracy: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.1414 - accuracy: 0.9549 - val_loss: 0.9600 - val_accuracy: 0.8170\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.1303 - accuracy: 0.9569 - val_loss: 0.9818 - val_accuracy: 0.7960\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.1268 - accuracy: 0.9564 - val_loss: 1.0258 - val_accuracy: 0.8030\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.9951 - val_accuracy: 0.8060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.1182 - accuracy: 0.9554 - val_loss: 1.1143 - val_accuracy: 0.7890\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.1119 - accuracy: 0.9580 - val_loss: 1.0550 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합(Overfitting : epoch가 늘어날수록 v이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 2.6719 - accuracy: 0.4999 - val_loss: 1.7653 - val_accuracy: 0.6490\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 1.4223 - accuracy: 0.7171 - val_loss: 1.3027 - val_accuracy: 0.7190\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 1.0465 - accuracy: 0.7781 - val_loss: 1.1344 - val_accuracy: 0.7560\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.8229 - accuracy: 0.8287 - val_loss: 1.0545 - val_accuracy: 0.7740\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.6553 - accuracy: 0.8636 - val_loss: 0.9817 - val_accuracy: 0.7950\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.5250 - accuracy: 0.8885 - val_loss: 0.9543 - val_accuracy: 0.8010\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.4226 - accuracy: 0.9110 - val_loss: 0.9141 - val_accuracy: 0.8050\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.3424 - accuracy: 0.9271 - val_loss: 0.9312 - val_accuracy: 0.8080\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 0.2846 - accuracy: 0.9351 - val_loss: 0.9143 - val_accuracy: 0.8100\n",
      "2246/2246 [==============================] - 0s 107us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9951549028564752, 0.7827248573303223]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19056099732858414"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])\n",
    "# 최댓값의 인덱스를 얻고자 할 때 쓰임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 3.0670 - accuracy: 0.3378 - val_loss: 2.4298 - val_accuracy: 0.3790\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 2.0181 - accuracy: 0.5081 - val_loss: 1.7805 - val_accuracy: 0.5460\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 1.6251 - accuracy: 0.5477 - val_loss: 1.6623 - val_accuracy: 0.5490\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 1.4915 - accuracy: 0.5650 - val_loss: 1.6498 - val_accuracy: 0.5810\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 1.4081 - accuracy: 0.5938 - val_loss: 1.6121 - val_accuracy: 0.5810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 1.3502 - accuracy: 0.5971 - val_loss: 1.6287 - val_accuracy: 0.5880\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 1.3035 - accuracy: 0.5993 - val_loss: 1.6032 - val_accuracy: 0.5920\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 1.2670 - accuracy: 0.6026 - val_loss: 1.6217 - val_accuracy: 0.5900\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 1.2353 - accuracy: 0.6029 - val_loss: 1.6963 - val_accuracy: 0.5880\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 1.2068 - accuracy: 0.6066 - val_loss: 1.6808 - val_accuracy: 0.5890\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 1.1805 - accuracy: 0.6095 - val_loss: 1.7432 - val_accuracy: 0.5910\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 1.1554 - accuracy: 0.6205 - val_loss: 1.7430 - val_accuracy: 0.6030\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 1.1312 - accuracy: 0.6348 - val_loss: 1.7779 - val_accuracy: 0.6120\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 1.1150 - accuracy: 0.6477 - val_loss: 1.8243 - val_accuracy: 0.6140\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 1.0936 - accuracy: 0.6689 - val_loss: 1.8817 - val_accuracy: 0.6160\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 1.0768 - accuracy: 0.6877 - val_loss: 1.8940 - val_accuracy: 0.6110\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 1.0601 - accuracy: 0.6913 - val_loss: 1.9261 - val_accuracy: 0.6210\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 1.0438 - accuracy: 0.7021 - val_loss: 2.0306 - val_accuracy: 0.6200\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 133us/step - loss: 1.0310 - accuracy: 0.7083 - val_loss: 2.0414 - val_accuracy: 0.6260\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 1.0172 - accuracy: 0.7071 - val_loss: 2.0841 - val_accuracy: 0.6280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f02efdbeb8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요.\n",
    "\n",
    "Q. 위에서 은닉층 왜 2개지..? 한개 쓴거 아닌가..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 1.7953 - accuracy: 0.6215 - val_loss: 1.2197 - val_accuracy: 0.7200\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.9599 - accuracy: 0.7912 - val_loss: 1.0283 - val_accuracy: 0.7740\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.6527 - accuracy: 0.8550 - val_loss: 0.9781 - val_accuracy: 0.7830\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.4492 - accuracy: 0.8994 - val_loss: 0.9416 - val_accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.3250 - accuracy: 0.9270 - val_loss: 0.9471 - val_accuracy: 0.8170\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.2497 - accuracy: 0.9432 - val_loss: 0.9967 - val_accuracy: 0.8080\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.2063 - accuracy: 0.9498 - val_loss: 1.0494 - val_accuracy: 0.8060\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.1843 - accuracy: 0.9528 - val_loss: 1.0347 - val_accuracy: 0.8110\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.1657 - accuracy: 0.9545 - val_loss: 1.1683 - val_accuracy: 0.7900\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.1541 - accuracy: 0.9549 - val_loss: 1.1156 - val_accuracy: 0.8060\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.1428 - accuracy: 0.9550 - val_loss: 1.1305 - val_accuracy: 0.8050\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.1330 - accuracy: 0.9572 - val_loss: 1.1723 - val_accuracy: 0.7990\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.1285 - accuracy: 0.9568 - val_loss: 1.1947 - val_accuracy: 0.7940\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.1204 - accuracy: 0.9575 - val_loss: 1.2681 - val_accuracy: 0.7940\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.1185 - accuracy: 0.9564 - val_loss: 1.2535 - val_accuracy: 0.7850\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.1091 - accuracy: 0.9589 - val_loss: 1.3305 - val_accuracy: 0.7920\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.1070 - accuracy: 0.9575 - val_loss: 1.3082 - val_accuracy: 0.7940\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1026 - accuracy: 0.9564 - val_loss: 1.3738 - val_accuracy: 0.7950\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1018 - accuracy: 0.9564 - val_loss: 1.4594 - val_accuracy: 0.7910\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.0980 - accuracy: 0.9565 - val_loss: 1.4427 - val_accuracy: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f06acd8898>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) #Input : 입력층\n",
    "model.add(layers.Dense(64, activation='relu')) # Hidden : 은닉층 (중간층의 히든 유닛이 64개인거임)\n",
    "model.add(layers.Dense(64, activation='relu')) # Hidden : 은닉층\n",
    "model.add(layers.Dense(46, activation='softmax')) # Output : 출력층\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉층 하나 더 썼더니 정확도가 약 96%로 올라갔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
