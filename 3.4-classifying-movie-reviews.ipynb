{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다. (현재 내가 사용하는 것은 케라스 버전 2.3.1 이다.)\n",
    "\n",
    "----\n",
    "\n",
    "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "\n",
    "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
    "\n",
    "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
    "\n",
    "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
    "\n",
    "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels),  = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
    "\n",
    "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:\n",
    "\n",
    "imdb 데이터셋은 train set 25000개, text set 25000개의 샘플을 제공한다. 라벨은 1과 0의 좋다, 싫다로 지정되어있다. 케라스에서 제공하는 imdb의 load_data() 함수를 이용하면 데이터 셋을 쉽게 얻을 수 있다. 데이터셋은 이미 정수로 인코딩되어 있고, 정수값은 단어의 빈도수를 나타낸다. 위의 코드는 가장 빈도수가 높게 나타난 단어 10000개로 데이터셋을 만든 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data는 array 안에 list가 여러개 들어있는 형태.\n",
    "array(list0, list1, list2, ... , list24999) 총 25000개 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "# 딕셔너리 reverse_word_index에서 key 값이 i-3인 value를 가져와서 ' '를 구분자로 하여 가져오는데, 없으면 '?'를 default로 돌려준다. 이때 key값에 사용되는 i는 train_data[0] 리스트에 있는 정수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34701: 'fawn',\n",
       " 52006: 'tsukino',\n",
       " 52007: 'nunnery',\n",
       " 16816: 'sonja',\n",
       " 63951: 'vani',\n",
       " 1408: 'woods',\n",
       " 16115: 'spiders',\n",
       " 2345: 'hanging',\n",
       " 2289: 'woody',\n",
       " 52008: 'trawling',\n",
       " 52009: \"hold's\",\n",
       " 11307: 'comically',\n",
       " 40830: 'localized',\n",
       " 30568: 'disobeying',\n",
       " 52010: \"'royale\",\n",
       " 40831: \"harpo's\",\n",
       " 52011: 'canet',\n",
       " 19313: 'aileen',\n",
       " 52012: 'acurately',\n",
       " 52013: \"diplomat's\",\n",
       " 25242: 'rickman',\n",
       " 6746: 'arranged',\n",
       " 52014: 'rumbustious',\n",
       " 52015: 'familiarness',\n",
       " 52016: \"spider'\",\n",
       " 68804: 'hahahah',\n",
       " 52017: \"wood'\",\n",
       " 40833: 'transvestism',\n",
       " 34702: \"hangin'\",\n",
       " 2338: 'bringing',\n",
       " 40834: 'seamier',\n",
       " 34703: 'wooded',\n",
       " 52018: 'bravora',\n",
       " 16817: 'grueling',\n",
       " 1636: 'wooden',\n",
       " 16818: 'wednesday',\n",
       " 52019: \"'prix\",\n",
       " 34704: 'altagracia',\n",
       " 52020: 'circuitry',\n",
       " 11585: 'crotch',\n",
       " 57766: 'busybody',\n",
       " 52021: \"tart'n'tangy\",\n",
       " 14129: 'burgade',\n",
       " 52023: 'thrace',\n",
       " 11038: \"tom's\",\n",
       " 52025: 'snuggles',\n",
       " 29114: 'francesco',\n",
       " 52027: 'complainers',\n",
       " 52125: 'templarios',\n",
       " 40835: '272',\n",
       " 52028: '273',\n",
       " 52130: 'zaniacs',\n",
       " 34706: '275',\n",
       " 27631: 'consenting',\n",
       " 40836: 'snuggled',\n",
       " 15492: 'inanimate',\n",
       " 52030: 'uality',\n",
       " 11926: 'bronte',\n",
       " 4010: 'errors',\n",
       " 3230: 'dialogs',\n",
       " 52031: \"yomada's\",\n",
       " 34707: \"madman's\",\n",
       " 30585: 'dialoge',\n",
       " 52033: 'usenet',\n",
       " 40837: 'videodrome',\n",
       " 26338: \"kid'\",\n",
       " 52034: 'pawed',\n",
       " 30569: \"'girlfriend'\",\n",
       " 52035: \"'pleasure\",\n",
       " 52036: \"'reloaded'\",\n",
       " 40839: \"kazakos'\",\n",
       " 52037: 'rocque',\n",
       " 52038: 'mailings',\n",
       " 11927: 'brainwashed',\n",
       " 16819: 'mcanally',\n",
       " 52039: \"tom''\",\n",
       " 25243: 'kurupt',\n",
       " 21905: 'affiliated',\n",
       " 52040: 'babaganoosh',\n",
       " 40840: \"noe's\",\n",
       " 40841: 'quart',\n",
       " 359: 'kids',\n",
       " 5034: 'uplifting',\n",
       " 7093: 'controversy',\n",
       " 21906: 'kida',\n",
       " 23379: 'kidd',\n",
       " 52041: \"error'\",\n",
       " 52042: 'neurologist',\n",
       " 18510: 'spotty',\n",
       " 30570: 'cobblers',\n",
       " 9878: 'projection',\n",
       " 40842: 'fastforwarding',\n",
       " 52043: 'sters',\n",
       " 52044: \"eggar's\",\n",
       " 52045: 'etherything',\n",
       " 40843: 'gateshead',\n",
       " 34708: 'airball',\n",
       " 25244: 'unsinkable',\n",
       " 7180: 'stern',\n",
       " 52046: \"cervi's\",\n",
       " 40844: 'dnd',\n",
       " 11586: 'dna',\n",
       " 20598: 'insecurity',\n",
       " 52047: \"'reboot'\",\n",
       " 11037: 'trelkovsky',\n",
       " 52048: 'jaekel',\n",
       " 52049: 'sidebars',\n",
       " 52050: \"sforza's\",\n",
       " 17633: 'distortions',\n",
       " 52051: 'mutinies',\n",
       " 30602: 'sermons',\n",
       " 40846: '7ft',\n",
       " 52052: 'boobage',\n",
       " 52053: \"o'bannon's\",\n",
       " 23380: 'populations',\n",
       " 52054: 'chulak',\n",
       " 27633: 'mesmerize',\n",
       " 52055: 'quinnell',\n",
       " 10307: 'yahoo',\n",
       " 52057: 'meteorologist',\n",
       " 42577: 'beswick',\n",
       " 15493: 'boorman',\n",
       " 40847: 'voicework',\n",
       " 52058: \"ster'\",\n",
       " 22922: 'blustering',\n",
       " 52059: 'hj',\n",
       " 27634: 'intake',\n",
       " 5621: 'morally',\n",
       " 40849: 'jumbling',\n",
       " 52060: 'bowersock',\n",
       " 52061: \"'porky's'\",\n",
       " 16821: 'gershon',\n",
       " 40850: 'ludicrosity',\n",
       " 52062: 'coprophilia',\n",
       " 40851: 'expressively',\n",
       " 19500: \"india's\",\n",
       " 34710: \"post's\",\n",
       " 52063: 'wana',\n",
       " 5283: 'wang',\n",
       " 30571: 'wand',\n",
       " 25245: 'wane',\n",
       " 52321: 'edgeways',\n",
       " 34711: 'titanium',\n",
       " 40852: 'pinta',\n",
       " 178: 'want',\n",
       " 30572: 'pinto',\n",
       " 52065: 'whoopdedoodles',\n",
       " 21908: 'tchaikovsky',\n",
       " 2103: 'travel',\n",
       " 52066: \"'victory'\",\n",
       " 11928: 'copious',\n",
       " 22433: 'gouge',\n",
       " 52067: \"chapters'\",\n",
       " 6702: 'barbra',\n",
       " 30573: 'uselessness',\n",
       " 52068: \"wan'\",\n",
       " 27635: 'assimilated',\n",
       " 16116: 'petiot',\n",
       " 52069: 'most\\x85and',\n",
       " 3930: 'dinosaurs',\n",
       " 352: 'wrong',\n",
       " 52070: 'seda',\n",
       " 52071: 'stollen',\n",
       " 34712: 'sentencing',\n",
       " 40853: 'ouroboros',\n",
       " 40854: 'assimilates',\n",
       " 40855: 'colorfully',\n",
       " 27636: 'glenne',\n",
       " 52072: 'dongen',\n",
       " 4760: 'subplots',\n",
       " 52073: 'kiloton',\n",
       " 23381: 'chandon',\n",
       " 34713: \"effect'\",\n",
       " 27637: 'snugly',\n",
       " 40856: 'kuei',\n",
       " 9092: 'welcomed',\n",
       " 30071: 'dishonor',\n",
       " 52075: 'concurrence',\n",
       " 23382: 'stoicism',\n",
       " 14896: \"guys'\",\n",
       " 52077: \"beroemd'\",\n",
       " 6703: 'butcher',\n",
       " 40857: \"melfi's\",\n",
       " 30623: 'aargh',\n",
       " 20599: 'playhouse',\n",
       " 11308: 'wickedly',\n",
       " 1180: 'fit',\n",
       " 52078: 'labratory',\n",
       " 40859: 'lifeline',\n",
       " 1927: 'screaming',\n",
       " 4287: 'fix',\n",
       " 52079: 'cineliterate',\n",
       " 52080: 'fic',\n",
       " 52081: 'fia',\n",
       " 34714: 'fig',\n",
       " 52082: 'fmvs',\n",
       " 52083: 'fie',\n",
       " 52084: 'reentered',\n",
       " 30574: 'fin',\n",
       " 52085: 'doctresses',\n",
       " 52086: 'fil',\n",
       " 12606: 'zucker',\n",
       " 31931: 'ached',\n",
       " 52088: 'counsil',\n",
       " 52089: 'paterfamilias',\n",
       " 13885: 'songwriter',\n",
       " 34715: 'shivam',\n",
       " 9654: 'hurting',\n",
       " 299: 'effects',\n",
       " 52090: 'slauther',\n",
       " 52091: \"'flame'\",\n",
       " 52092: 'sommerset',\n",
       " 52093: 'interwhined',\n",
       " 27638: 'whacking',\n",
       " 52094: 'bartok',\n",
       " 8775: 'barton',\n",
       " 21909: 'frewer',\n",
       " 52095: \"fi'\",\n",
       " 6192: 'ingrid',\n",
       " 30575: 'stribor',\n",
       " 52096: 'approporiately',\n",
       " 52097: 'wobblyhand',\n",
       " 52098: 'tantalisingly',\n",
       " 52099: 'ankylosaurus',\n",
       " 17634: 'parasites',\n",
       " 52100: 'childen',\n",
       " 52101: \"jenkins'\",\n",
       " 52102: 'metafiction',\n",
       " 17635: 'golem',\n",
       " 40860: 'indiscretion',\n",
       " 23383: \"reeves'\",\n",
       " 57781: \"inamorata's\",\n",
       " 52104: 'brittannica',\n",
       " 7916: 'adapt',\n",
       " 30576: \"russo's\",\n",
       " 48246: 'guitarists',\n",
       " 10553: 'abbott',\n",
       " 40861: 'abbots',\n",
       " 17649: 'lanisha',\n",
       " 40863: 'magickal',\n",
       " 52105: 'mattter',\n",
       " 52106: \"'willy\",\n",
       " 34716: 'pumpkins',\n",
       " 52107: 'stuntpeople',\n",
       " 30577: 'estimate',\n",
       " 40864: 'ugghhh',\n",
       " 11309: 'gameplay',\n",
       " 52108: \"wern't\",\n",
       " 40865: \"n'sync\",\n",
       " 16117: 'sickeningly',\n",
       " 40866: 'chiara',\n",
       " 4011: 'disturbed',\n",
       " 40867: 'portmanteau',\n",
       " 52109: 'ineffectively',\n",
       " 82143: \"duchonvey's\",\n",
       " 37519: \"nasty'\",\n",
       " 1285: 'purpose',\n",
       " 52112: 'lazers',\n",
       " 28105: 'lightened',\n",
       " 52113: 'kaliganj',\n",
       " 52114: 'popularism',\n",
       " 18511: \"damme's\",\n",
       " 30578: 'stylistics',\n",
       " 52115: 'mindgaming',\n",
       " 46449: 'spoilerish',\n",
       " 52117: \"'corny'\",\n",
       " 34718: 'boerner',\n",
       " 6792: 'olds',\n",
       " 52118: 'bakelite',\n",
       " 27639: 'renovated',\n",
       " 27640: 'forrester',\n",
       " 52119: \"lumiere's\",\n",
       " 52024: 'gaskets',\n",
       " 884: 'needed',\n",
       " 34719: 'smight',\n",
       " 1297: 'master',\n",
       " 25905: \"edie's\",\n",
       " 40868: 'seeber',\n",
       " 52120: 'hiya',\n",
       " 52121: 'fuzziness',\n",
       " 14897: 'genesis',\n",
       " 12607: 'rewards',\n",
       " 30579: 'enthrall',\n",
       " 40869: \"'about\",\n",
       " 52122: \"recollection's\",\n",
       " 11039: 'mutilated',\n",
       " 52123: 'fatherlands',\n",
       " 52124: \"fischer's\",\n",
       " 5399: 'positively',\n",
       " 34705: '270',\n",
       " 34720: 'ahmed',\n",
       " 9836: 'zatoichi',\n",
       " 13886: 'bannister',\n",
       " 52127: 'anniversaries',\n",
       " 30580: \"helm's\",\n",
       " 52128: \"'work'\",\n",
       " 34721: 'exclaimed',\n",
       " 52129: \"'unfunny'\",\n",
       " 52029: '274',\n",
       " 544: 'feeling',\n",
       " 52131: \"wanda's\",\n",
       " 33266: 'dolan',\n",
       " 52133: '278',\n",
       " 52134: 'peacoat',\n",
       " 40870: 'brawny',\n",
       " 40871: 'mishra',\n",
       " 40872: 'worlders',\n",
       " 52135: 'protags',\n",
       " 52136: 'skullcap',\n",
       " 57596: 'dastagir',\n",
       " 5622: 'affairs',\n",
       " 7799: 'wholesome',\n",
       " 52137: 'hymen',\n",
       " 25246: 'paramedics',\n",
       " 52138: 'unpersons',\n",
       " 52139: 'heavyarms',\n",
       " 52140: 'affaire',\n",
       " 52141: 'coulisses',\n",
       " 40873: 'hymer',\n",
       " 52142: 'kremlin',\n",
       " 30581: 'shipments',\n",
       " 52143: 'pixilated',\n",
       " 30582: \"'00s\",\n",
       " 18512: 'diminishing',\n",
       " 1357: 'cinematic',\n",
       " 14898: 'resonates',\n",
       " 40874: 'simplify',\n",
       " 40875: \"nature'\",\n",
       " 40876: 'temptresses',\n",
       " 16822: 'reverence',\n",
       " 19502: 'resonated',\n",
       " 34722: 'dailey',\n",
       " 52144: '2\\x85',\n",
       " 27641: 'treize',\n",
       " 52145: 'majo',\n",
       " 21910: 'kiya',\n",
       " 52146: 'woolnough',\n",
       " 39797: 'thanatos',\n",
       " 35731: 'sandoval',\n",
       " 40879: 'dorama',\n",
       " 52147: \"o'shaughnessy\",\n",
       " 4988: 'tech',\n",
       " 32018: 'fugitives',\n",
       " 30583: 'teck',\n",
       " 76125: \"'e'\",\n",
       " 40881: 'doesn’t',\n",
       " 52149: 'purged',\n",
       " 657: 'saying',\n",
       " 41095: \"martians'\",\n",
       " 23418: 'norliss',\n",
       " 27642: 'dickey',\n",
       " 52152: 'dicker',\n",
       " 52153: \"'sependipity\",\n",
       " 8422: 'padded',\n",
       " 57792: 'ordell',\n",
       " 40882: \"sturges'\",\n",
       " 52154: 'independentcritics',\n",
       " 5745: 'tempted',\n",
       " 34724: \"atkinson's\",\n",
       " 25247: 'hounded',\n",
       " 52155: 'apace',\n",
       " 15494: 'clicked',\n",
       " 30584: \"'humor'\",\n",
       " 17177: \"martino's\",\n",
       " 52156: \"'supporting\",\n",
       " 52032: 'warmongering',\n",
       " 34725: \"zemeckis's\",\n",
       " 21911: 'lube',\n",
       " 52157: 'shocky',\n",
       " 7476: 'plate',\n",
       " 40883: 'plata',\n",
       " 40884: 'sturgess',\n",
       " 40885: \"nerds'\",\n",
       " 20600: 'plato',\n",
       " 34726: 'plath',\n",
       " 40886: 'platt',\n",
       " 52159: 'mcnab',\n",
       " 27643: 'clumsiness',\n",
       " 3899: 'altogether',\n",
       " 42584: 'massacring',\n",
       " 52160: 'bicenntinial',\n",
       " 40887: 'skaal',\n",
       " 14360: 'droning',\n",
       " 8776: 'lds',\n",
       " 21912: 'jaguar',\n",
       " 34727: \"cale's\",\n",
       " 1777: 'nicely',\n",
       " 4588: 'mummy',\n",
       " 18513: \"lot's\",\n",
       " 10086: 'patch',\n",
       " 50202: 'kerkhof',\n",
       " 52161: \"leader's\",\n",
       " 27644: \"'movie\",\n",
       " 52162: 'uncomfirmed',\n",
       " 40888: 'heirloom',\n",
       " 47360: 'wrangle',\n",
       " 52163: 'emotion\\x85',\n",
       " 52164: \"'stargate'\",\n",
       " 40889: 'pinoy',\n",
       " 40890: 'conchatta',\n",
       " 41128: 'broeke',\n",
       " 40891: 'advisedly',\n",
       " 17636: \"barker's\",\n",
       " 52166: 'descours',\n",
       " 772: 'lots',\n",
       " 9259: 'lotr',\n",
       " 9879: 'irs',\n",
       " 52167: 'lott',\n",
       " 40892: 'xvi',\n",
       " 34728: 'irk',\n",
       " 52168: 'irl',\n",
       " 6887: 'ira',\n",
       " 21913: 'belzer',\n",
       " 52169: 'irc',\n",
       " 27645: 'ire',\n",
       " 40893: 'requisites',\n",
       " 7693: 'discipline',\n",
       " 52961: 'lyoko',\n",
       " 11310: 'extend',\n",
       " 873: 'nature',\n",
       " 52170: \"'dickie'\",\n",
       " 40894: 'optimist',\n",
       " 30586: 'lapping',\n",
       " 3900: 'superficial',\n",
       " 52171: 'vestment',\n",
       " 2823: 'extent',\n",
       " 52172: 'tendons',\n",
       " 52173: \"heller's\",\n",
       " 52174: 'quagmires',\n",
       " 52175: 'miyako',\n",
       " 20601: 'moocow',\n",
       " 52176: \"coles'\",\n",
       " 40895: 'lookit',\n",
       " 52177: 'ravenously',\n",
       " 40896: 'levitating',\n",
       " 52178: 'perfunctorily',\n",
       " 30587: 'lookin',\n",
       " 40898: \"lot'\",\n",
       " 52179: 'lookie',\n",
       " 34870: 'fearlessly',\n",
       " 52181: 'libyan',\n",
       " 40899: 'fondles',\n",
       " 35714: 'gopher',\n",
       " 40901: 'wearying',\n",
       " 52182: \"nz's\",\n",
       " 27646: 'minuses',\n",
       " 52183: 'puposelessly',\n",
       " 52184: 'shandling',\n",
       " 31268: 'decapitates',\n",
       " 11929: 'humming',\n",
       " 40902: \"'nother\",\n",
       " 21914: 'smackdown',\n",
       " 30588: 'underdone',\n",
       " 40903: 'frf',\n",
       " 52185: 'triviality',\n",
       " 25248: 'fro',\n",
       " 8777: 'bothers',\n",
       " 52186: \"'kensington\",\n",
       " 73: 'much',\n",
       " 34730: 'muco',\n",
       " 22615: 'wiseguy',\n",
       " 27648: \"richie's\",\n",
       " 40904: 'tonino',\n",
       " 52187: 'unleavened',\n",
       " 11587: 'fry',\n",
       " 40905: \"'tv'\",\n",
       " 40906: 'toning',\n",
       " 14361: 'obese',\n",
       " 30589: 'sensationalized',\n",
       " 40907: 'spiv',\n",
       " 6259: 'spit',\n",
       " 7364: 'arkin',\n",
       " 21915: 'charleton',\n",
       " 16823: 'jeon',\n",
       " 21916: 'boardroom',\n",
       " 4989: 'doubts',\n",
       " 3084: 'spin',\n",
       " 53083: 'hepo',\n",
       " 27649: 'wildcat',\n",
       " 10584: 'venoms',\n",
       " 52191: 'misconstrues',\n",
       " 18514: 'mesmerising',\n",
       " 40908: 'misconstrued',\n",
       " 52192: 'rescinds',\n",
       " 52193: 'prostrate',\n",
       " 40909: 'majid',\n",
       " 16479: 'climbed',\n",
       " 34731: 'canoeing',\n",
       " 52195: 'majin',\n",
       " 57804: 'animie',\n",
       " 40910: 'sylke',\n",
       " 14899: 'conditioned',\n",
       " 40911: 'waddell',\n",
       " 52196: '3\\x85',\n",
       " 41188: 'hyperdrive',\n",
       " 34732: 'conditioner',\n",
       " 53153: 'bricklayer',\n",
       " 2576: 'hong',\n",
       " 52198: 'memoriam',\n",
       " 30592: 'inventively',\n",
       " 25249: \"levant's\",\n",
       " 20638: 'portobello',\n",
       " 52200: 'remand',\n",
       " 19504: 'mummified',\n",
       " 27650: 'honk',\n",
       " 19505: 'spews',\n",
       " 40912: 'visitations',\n",
       " 52201: 'mummifies',\n",
       " 25250: 'cavanaugh',\n",
       " 23385: 'zeon',\n",
       " 40913: \"jungle's\",\n",
       " 34733: 'viertel',\n",
       " 27651: 'frenchmen',\n",
       " 52202: 'torpedoes',\n",
       " 52203: 'schlessinger',\n",
       " 34734: 'torpedoed',\n",
       " 69876: 'blister',\n",
       " 52204: 'cinefest',\n",
       " 34735: 'furlough',\n",
       " 52205: 'mainsequence',\n",
       " 40914: 'mentors',\n",
       " 9094: 'academic',\n",
       " 20602: 'stillness',\n",
       " 40915: 'academia',\n",
       " 52206: 'lonelier',\n",
       " 52207: 'nibby',\n",
       " 52208: \"losers'\",\n",
       " 40916: 'cineastes',\n",
       " 4449: 'corporate',\n",
       " 40917: 'massaging',\n",
       " 30593: 'bellow',\n",
       " 19506: 'absurdities',\n",
       " 53241: 'expetations',\n",
       " 40918: 'nyfiken',\n",
       " 75638: 'mehras',\n",
       " 52209: 'lasse',\n",
       " 52210: 'visability',\n",
       " 33946: 'militarily',\n",
       " 52211: \"elder'\",\n",
       " 19023: 'gainsbourg',\n",
       " 20603: 'hah',\n",
       " 13420: 'hai',\n",
       " 34736: 'haj',\n",
       " 25251: 'hak',\n",
       " 4311: 'hal',\n",
       " 4892: 'ham',\n",
       " 53259: 'duffer',\n",
       " 52213: 'haa',\n",
       " 66: 'had',\n",
       " 11930: 'advancement',\n",
       " 16825: 'hag',\n",
       " 25252: \"hand'\",\n",
       " 13421: 'hay',\n",
       " 20604: 'mcnamara',\n",
       " 52214: \"mozart's\",\n",
       " 30731: 'duffel',\n",
       " 30594: 'haq',\n",
       " 13887: 'har',\n",
       " 44: 'has',\n",
       " 2401: 'hat',\n",
       " 40919: 'hav',\n",
       " 30595: 'haw',\n",
       " 52215: 'figtings',\n",
       " 15495: 'elders',\n",
       " 52216: 'underpanted',\n",
       " 52217: 'pninson',\n",
       " 27652: 'unequivocally',\n",
       " 23673: \"barbara's\",\n",
       " 52219: \"bello'\",\n",
       " 12997: 'indicative',\n",
       " 40920: 'yawnfest',\n",
       " 52220: 'hexploitation',\n",
       " 52221: \"loder's\",\n",
       " 27653: 'sleuthing',\n",
       " 32622: \"justin's\",\n",
       " 52222: \"'ball\",\n",
       " 52223: \"'summer\",\n",
       " 34935: \"'demons'\",\n",
       " 52225: \"mormon's\",\n",
       " 34737: \"laughton's\",\n",
       " 52226: 'debell',\n",
       " 39724: 'shipyard',\n",
       " 30597: 'unabashedly',\n",
       " 40401: 'disks',\n",
       " 2290: 'crowd',\n",
       " 10087: 'crowe',\n",
       " 56434: \"vancouver's\",\n",
       " 34738: 'mosques',\n",
       " 6627: 'crown',\n",
       " 52227: 'culpas',\n",
       " 27654: 'crows',\n",
       " 53344: 'surrell',\n",
       " 52229: 'flowless',\n",
       " 52230: 'sheirk',\n",
       " 40923: \"'three\",\n",
       " 52231: \"peterson'\",\n",
       " 52232: 'ooverall',\n",
       " 40924: 'perchance',\n",
       " 1321: 'bottom',\n",
       " 53363: 'chabert',\n",
       " 52233: 'sneha',\n",
       " 13888: 'inhuman',\n",
       " 52234: 'ichii',\n",
       " 52235: 'ursla',\n",
       " 30598: 'completly',\n",
       " 40925: 'moviedom',\n",
       " 52236: 'raddick',\n",
       " 51995: 'brundage',\n",
       " 40926: 'brigades',\n",
       " 1181: 'starring',\n",
       " 52237: \"'goal'\",\n",
       " 52238: 'caskets',\n",
       " 52239: 'willcock',\n",
       " 52240: \"threesome's\",\n",
       " 52241: \"mosque'\",\n",
       " 52242: \"cover's\",\n",
       " 17637: 'spaceships',\n",
       " 40927: 'anomalous',\n",
       " 27655: 'ptsd',\n",
       " 52243: 'shirdan',\n",
       " 21962: 'obscenity',\n",
       " 30599: 'lemmings',\n",
       " 30600: 'duccio',\n",
       " 52244: \"levene's\",\n",
       " 52245: \"'gorby'\",\n",
       " 25255: \"teenager's\",\n",
       " 5340: 'marshall',\n",
       " 9095: 'honeymoon',\n",
       " 3231: 'shoots',\n",
       " 12258: 'despised',\n",
       " 52246: 'okabasho',\n",
       " 8289: 'fabric',\n",
       " 18515: 'cannavale',\n",
       " 3537: 'raped',\n",
       " 52247: \"tutt's\",\n",
       " 17638: 'grasping',\n",
       " 18516: 'despises',\n",
       " 40928: \"thief's\",\n",
       " 8926: 'rapes',\n",
       " 52248: 'raper',\n",
       " 27656: \"eyre'\",\n",
       " 52249: 'walchek',\n",
       " 23386: \"elmo's\",\n",
       " 40929: 'perfumes',\n",
       " 21918: 'spurting',\n",
       " 52250: \"exposition'\\x85\",\n",
       " 52251: 'denoting',\n",
       " 34740: 'thesaurus',\n",
       " 40930: \"shoot'\",\n",
       " 49759: 'bonejack',\n",
       " 52253: 'simpsonian',\n",
       " 30601: 'hebetude',\n",
       " 34741: \"hallow's\",\n",
       " 52254: 'desperation\\x85',\n",
       " 34742: 'incinerator',\n",
       " 10308: 'congratulations',\n",
       " 52255: 'humbled',\n",
       " 5924: \"else's\",\n",
       " 40845: 'trelkovski',\n",
       " 52256: \"rape'\",\n",
       " 59386: \"'chapters'\",\n",
       " 52257: '1600s',\n",
       " 7253: 'martian',\n",
       " 25256: 'nicest',\n",
       " 52259: 'eyred',\n",
       " 9457: 'passenger',\n",
       " 6041: 'disgrace',\n",
       " 52260: 'moderne',\n",
       " 5120: 'barrymore',\n",
       " 52261: 'yankovich',\n",
       " 40931: 'moderns',\n",
       " 52262: 'studliest',\n",
       " 52263: 'bedsheet',\n",
       " 14900: 'decapitation',\n",
       " 52264: 'slurring',\n",
       " 52265: \"'nunsploitation'\",\n",
       " 34743: \"'character'\",\n",
       " 9880: 'cambodia',\n",
       " 52266: 'rebelious',\n",
       " 27657: 'pasadena',\n",
       " 40932: 'crowne',\n",
       " 52267: \"'bedchamber\",\n",
       " 52268: 'conjectural',\n",
       " 52269: 'appologize',\n",
       " 52270: 'halfassing',\n",
       " 57816: 'paycheque',\n",
       " 20606: 'palms',\n",
       " 52271: \"'islands\",\n",
       " 40933: 'hawked',\n",
       " 21919: 'palme',\n",
       " 40934: 'conservatively',\n",
       " 64007: 'larp',\n",
       " 5558: 'palma',\n",
       " 21920: 'smelling',\n",
       " 12998: 'aragorn',\n",
       " 52272: 'hawker',\n",
       " 52273: 'hawkes',\n",
       " 3975: 'explosions',\n",
       " 8059: 'loren',\n",
       " 52274: \"pyle's\",\n",
       " 6704: 'shootout',\n",
       " 18517: \"mike's\",\n",
       " 52275: \"driscoll's\",\n",
       " 40935: 'cogsworth',\n",
       " 52276: \"britian's\",\n",
       " 34744: 'childs',\n",
       " 52277: \"portrait's\",\n",
       " 3626: 'chain',\n",
       " 2497: 'whoever',\n",
       " 52278: 'puttered',\n",
       " 52279: 'childe',\n",
       " 52280: 'maywether',\n",
       " 3036: 'chair',\n",
       " 52281: \"rance's\",\n",
       " 34745: 'machu',\n",
       " 4517: 'ballet',\n",
       " 34746: 'grapples',\n",
       " 76152: 'summerize',\n",
       " 30603: 'freelance',\n",
       " 52283: \"andrea's\",\n",
       " 52284: '\\x91very',\n",
       " 45879: 'coolidge',\n",
       " 18518: 'mache',\n",
       " 52285: 'balled',\n",
       " 40937: 'grappled',\n",
       " 18519: 'macha',\n",
       " 21921: 'underlining',\n",
       " 5623: 'macho',\n",
       " 19507: 'oversight',\n",
       " 25257: 'machi',\n",
       " 11311: 'verbally',\n",
       " 21922: 'tenacious',\n",
       " 40938: 'windshields',\n",
       " 18557: 'paychecks',\n",
       " 3396: 'jerk',\n",
       " 11931: \"good'\",\n",
       " 34748: 'prancer',\n",
       " 21923: 'prances',\n",
       " 52286: 'olympus',\n",
       " 21924: 'lark',\n",
       " 10785: 'embark',\n",
       " 7365: 'gloomy',\n",
       " 52287: 'jehaan',\n",
       " 52288: 'turaqui',\n",
       " 20607: \"child'\",\n",
       " 2894: 'locked',\n",
       " 52289: 'pranced',\n",
       " 2588: 'exact',\n",
       " 52290: 'unattuned',\n",
       " 783: 'minute',\n",
       " 16118: 'skewed',\n",
       " 40940: 'hodgins',\n",
       " 34749: 'skewer',\n",
       " 52291: 'think\\x85',\n",
       " 38765: 'rosenstein',\n",
       " 52292: 'helmit',\n",
       " 34750: 'wrestlemanias',\n",
       " 16826: 'hindered',\n",
       " 30604: \"martha's\",\n",
       " 52293: 'cheree',\n",
       " 52294: \"pluckin'\",\n",
       " 40941: 'ogles',\n",
       " 11932: 'heavyweight',\n",
       " 82190: 'aada',\n",
       " 11312: 'chopping',\n",
       " 61534: 'strongboy',\n",
       " 41342: 'hegemonic',\n",
       " 40942: 'adorns',\n",
       " 41346: 'xxth',\n",
       " 34751: 'nobuhiro',\n",
       " 52298: 'capitães',\n",
       " 52299: 'kavogianni',\n",
       " 13422: 'antwerp',\n",
       " 6538: 'celebrated',\n",
       " 52300: 'roarke',\n",
       " 40943: 'baggins',\n",
       " 31270: 'cheeseburgers',\n",
       " 52301: 'matras',\n",
       " 52302: \"nineties'\",\n",
       " 52303: \"'craig'\",\n",
       " 12999: 'celebrates',\n",
       " 3383: 'unintentionally',\n",
       " 14362: 'drafted',\n",
       " 52304: 'climby',\n",
       " 52305: '303',\n",
       " 18520: 'oldies',\n",
       " 9096: 'climbs',\n",
       " 9655: 'honour',\n",
       " 34752: 'plucking',\n",
       " 30074: '305',\n",
       " 5514: 'address',\n",
       " 40944: 'menjou',\n",
       " 42592: \"'freak'\",\n",
       " 19508: 'dwindling',\n",
       " 9458: 'benson',\n",
       " 52307: 'white’s',\n",
       " 40945: 'shamelessness',\n",
       " 21925: 'impacted',\n",
       " 52308: 'upatz',\n",
       " 3840: 'cusack',\n",
       " 37567: \"flavia's\",\n",
       " 52309: 'effette',\n",
       " 34753: 'influx',\n",
       " 52310: 'boooooooo',\n",
       " 52311: 'dimitrova',\n",
       " 13423: 'houseman',\n",
       " 25259: 'bigas',\n",
       " 52312: 'boylen',\n",
       " 52313: 'phillipenes',\n",
       " 40946: 'fakery',\n",
       " 27658: \"grandpa's\",\n",
       " 27659: 'darnell',\n",
       " 19509: 'undergone',\n",
       " 52315: 'handbags',\n",
       " 21926: 'perished',\n",
       " 37778: 'pooped',\n",
       " 27660: 'vigour',\n",
       " 3627: 'opposed',\n",
       " 52316: 'etude',\n",
       " 11799: \"caine's\",\n",
       " 52317: 'doozers',\n",
       " 34754: 'photojournals',\n",
       " 52318: 'perishes',\n",
       " 34755: 'constrains',\n",
       " 40948: 'migenes',\n",
       " 30605: 'consoled',\n",
       " 16827: 'alastair',\n",
       " 52319: 'wvs',\n",
       " 52320: 'ooooooh',\n",
       " 34756: 'approving',\n",
       " 40949: 'consoles',\n",
       " 52064: 'disparagement',\n",
       " 52322: 'futureistic',\n",
       " 52323: 'rebounding',\n",
       " 52324: \"'date\",\n",
       " 52325: 'gregoire',\n",
       " 21927: 'rutherford',\n",
       " 34757: 'americanised',\n",
       " 82196: 'novikov',\n",
       " 1042: 'following',\n",
       " 34758: 'munroe',\n",
       " 52326: \"morita'\",\n",
       " 52327: 'christenssen',\n",
       " 23106: 'oatmeal',\n",
       " 25260: 'fossey',\n",
       " 40950: 'livered',\n",
       " 13000: 'listens',\n",
       " 76164: \"'marci\",\n",
       " 52330: \"otis's\",\n",
       " 23387: 'thanking',\n",
       " 16019: 'maude',\n",
       " 34759: 'extensions',\n",
       " 52332: 'ameteurish',\n",
       " 52333: \"commender's\",\n",
       " 27661: 'agricultural',\n",
       " 4518: 'convincingly',\n",
       " 17639: 'fueled',\n",
       " 54014: 'mahattan',\n",
       " 40952: \"paris's\",\n",
       " 52336: 'vulkan',\n",
       " 52337: 'stapes',\n",
       " 52338: 'odysessy',\n",
       " 12259: 'harmon',\n",
       " 4252: 'surfing',\n",
       " 23494: 'halloran',\n",
       " 49580: 'unbelieveably',\n",
       " 52339: \"'offed'\",\n",
       " 30607: 'quadrant',\n",
       " 19510: 'inhabiting',\n",
       " 34760: 'nebbish',\n",
       " 40953: 'forebears',\n",
       " 34761: 'skirmish',\n",
       " 52340: 'ocassionally',\n",
       " 52341: \"'resist\",\n",
       " 21928: 'impactful',\n",
       " 52342: 'spicier',\n",
       " 40954: 'touristy',\n",
       " 52343: \"'football'\",\n",
       " 40955: 'webpage',\n",
       " 52345: 'exurbia',\n",
       " 52346: 'jucier',\n",
       " 14901: 'professors',\n",
       " 34762: 'structuring',\n",
       " 30608: 'jig',\n",
       " 40956: 'overlord',\n",
       " 25261: 'disconnect',\n",
       " 82201: 'sniffle',\n",
       " 40957: 'slimeball',\n",
       " 40958: 'jia',\n",
       " 16828: 'milked',\n",
       " 40959: 'banjoes',\n",
       " 1237: 'jim',\n",
       " 52348: 'workforces',\n",
       " 52349: 'jip',\n",
       " 52350: 'rotweiller',\n",
       " 34763: 'mundaneness',\n",
       " 52351: \"'ninja'\",\n",
       " 11040: \"dead'\",\n",
       " 40960: \"cipriani's\",\n",
       " 20608: 'modestly',\n",
       " 52352: \"professor'\",\n",
       " 40961: 'shacked',\n",
       " 34764: 'bashful',\n",
       " 23388: 'sorter',\n",
       " 16120: 'overpowering',\n",
       " 18521: 'workmanlike',\n",
       " 27662: 'henpecked',\n",
       " 18522: 'sorted',\n",
       " 52354: \"jōb's\",\n",
       " 52355: \"'always\",\n",
       " 34765: \"'baptists\",\n",
       " 52356: 'dreamcatchers',\n",
       " 52357: \"'silence'\",\n",
       " 21929: 'hickory',\n",
       " 52358: 'fun\\x97yet',\n",
       " 52359: 'breakumentary',\n",
       " 15496: 'didn',\n",
       " 52360: 'didi',\n",
       " 52361: 'pealing',\n",
       " 40962: 'dispite',\n",
       " 25262: \"italy's\",\n",
       " 21930: 'instability',\n",
       " 6539: 'quarter',\n",
       " 12608: 'quartet',\n",
       " 52362: 'padmé',\n",
       " 52363: \"'bleedmedry\",\n",
       " 52364: 'pahalniuk',\n",
       " 52365: 'honduras',\n",
       " 10786: 'bursting',\n",
       " 41465: \"pablo's\",\n",
       " 52367: 'irremediably',\n",
       " 40963: 'presages',\n",
       " 57832: 'bowlegged',\n",
       " 65183: 'dalip',\n",
       " 6260: 'entering',\n",
       " 76172: 'newsradio',\n",
       " 54150: 'presaged',\n",
       " 27663: \"giallo's\",\n",
       " 40964: 'bouyant',\n",
       " 52368: 'amerterish',\n",
       " 18523: 'rajni',\n",
       " 30610: 'leeves',\n",
       " 34767: 'macauley',\n",
       " 612: 'seriously',\n",
       " 52369: 'sugercoma',\n",
       " 52370: 'grimstead',\n",
       " 52371: \"'fairy'\",\n",
       " 30611: 'zenda',\n",
       " 52372: \"'twins'\",\n",
       " 17640: 'realisation',\n",
       " 27664: 'highsmith',\n",
       " 7817: 'raunchy',\n",
       " 40965: 'incentives',\n",
       " 52374: 'flatson',\n",
       " 35097: 'snooker',\n",
       " 16829: 'crazies',\n",
       " 14902: 'crazier',\n",
       " 7094: 'grandma',\n",
       " 52375: 'napunsaktha',\n",
       " 30612: 'workmanship',\n",
       " 52376: 'reisner',\n",
       " 61306: \"sanford's\",\n",
       " 52377: '\\x91doña',\n",
       " 6108: 'modest',\n",
       " 19153: \"everything's\",\n",
       " 40966: 'hamer',\n",
       " 52379: \"couldn't'\",\n",
       " 13001: 'quibble',\n",
       " 52380: 'socking',\n",
       " 21931: 'tingler',\n",
       " 52381: 'gutman',\n",
       " 40967: 'lachlan',\n",
       " 52382: 'tableaus',\n",
       " 52383: 'headbanger',\n",
       " 2847: 'spoken',\n",
       " 34768: 'cerebrally',\n",
       " 23490: \"'road\",\n",
       " 21932: 'tableaux',\n",
       " 40968: \"proust's\",\n",
       " 40969: 'periodical',\n",
       " 52385: \"shoveller's\",\n",
       " 25263: 'tamara',\n",
       " 17641: 'affords',\n",
       " 3249: 'concert',\n",
       " 87955: \"yara's\",\n",
       " 52386: 'someome',\n",
       " 8424: 'lingering',\n",
       " 41511: \"abraham's\",\n",
       " 34769: 'beesley',\n",
       " 34770: 'cherbourg',\n",
       " 28624: 'kagan',\n",
       " 9097: 'snatch',\n",
       " 9260: \"miyazaki's\",\n",
       " 25264: 'absorbs',\n",
       " 40970: \"koltai's\",\n",
       " 64027: 'tingled',\n",
       " 19511: 'crossroads',\n",
       " 16121: 'rehab',\n",
       " 52389: 'falworth',\n",
       " 52390: 'sequals',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index\n",
    "# word_index에 있는 items를 가져와서, 거기에 있는 key, value를 value, key 로 딕셔너리화 한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
    "\n",
    "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
    "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
    "* 원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식이다. 이렇게 표현된 벡터를 원-핫 벡터(One-hot vector)라고 한다.\n",
    "\n",
    "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        # 리스트 sequences 의 순서 i, 리스트값 sequence를 가져온다.\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 샘플은 다음과 같이 나타납니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망에 주입할 데이터가 준비되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 만들기\n",
    "\n",
    "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
    "\n",
    "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. <b>은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).</b>\n",
    "\n",
    "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
    "\n",
    "* 얼마나 많은 층을 사용할 것인가\n",
    "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
    "\n",
    "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
    "\n",
    "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
    "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
    "\n",
    "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음이 이 신경망의 모습입니다:\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
    "\n",
    "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 옵티마이저를 이와 같이 이름으로 사용하면, 해당 옵티마이저의 기본 설정이 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잘 모르겠다 다시 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저의 이름을 사용하는 경우 : 기본 설정이 사용된다.\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아 여기서 metrics=[metrics.binary_accuracy] 를 안했어서 아래부분에서 acc KeyError 난 거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저의 매개변수를 바꾸거나\n",
    "# 자신만의 손실 함수, 측정함수를 전달하기 위해서\n",
    "# 객체 (여기서는 sgd)를 직접 만들어서, model.compile()의 매개변수로 전달해서 쓸 수도 있다.\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서도 accuracy 안넣어서 KeyError 났음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['acc']로 하면 history에서 key 가 acc, val_acc 로 바뀐다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loss == 손실함수 : 학습을 통해 직접적으로 줄이고자 하는 값 (loss(손실) = error(에러) = cost(코스트))\n",
    "* metrics == 측정함수 : 학습을 통해 목표를 얼마나 잘(못) 달성했는지를 나타내는 값, metric(척도)\n",
    "* 머신러닝의 최종 목표는 척도로 달성률을 표시하지만,\n",
    "* 직접 척도를 낮추도록 훈련하는 것은 어렵기때문에 손실을 줄이는 방향으로 훈련한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "# 리스트 x_train에서 index 값이 0 이상 10000미만인 값들을 떼어내서 리스트 x_val을 만든다.\n",
    "partial_x_train = x_train[10000:]\n",
    "# 리스트 x_train에서 index 값이 10000 이상인 값들을 떼어내서 리스트 partial_x_train을 만든다.\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 2s 130us/step - loss: 0.0327 - acc: 0.9714 - val_loss: 0.0905 - val_acc: 0.8768\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.0319 - acc: 0.9725 - val_loss: 0.0907 - val_acc: 0.8767\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 120us/step - loss: 0.0311 - acc: 0.9735 - val_loss: 0.0912 - val_acc: 0.8775\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 120us/step - loss: 0.0302 - acc: 0.9739 - val_loss: 0.0913 - val_acc: 0.8755\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0296 - acc: 0.9749 - val_loss: 0.0915 - val_acc: 0.8763\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 120us/step - loss: 0.0288 - acc: 0.9764 - val_loss: 0.0925 - val_acc: 0.8764\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.0281 - acc: 0.9765 - val_loss: 0.0920 - val_acc: 0.8757\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0274 - acc: 0.9778 - val_loss: 0.0926 - val_acc: 0.8755\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 120us/step - loss: 0.0267 - acc: 0.9792 - val_loss: 0.0928 - val_acc: 0.8751\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0260 - acc: 0.9800 - val_loss: 0.0929 - val_acc: 0.8750\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0254 - acc: 0.9800 - val_loss: 0.0935 - val_acc: 0.8759\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0247 - acc: 0.9812 - val_loss: 0.0943 - val_acc: 0.8734\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0244 - acc: 0.9809 - val_loss: 0.0942 - val_acc: 0.8736\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0237 - acc: 0.9818 - val_loss: 0.0942 - val_acc: 0.8747\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0232 - acc: 0.9827 - val_loss: 0.0944 - val_acc: 0.8753\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0227 - acc: 0.9834 - val_loss: 0.0947 - val_acc: 0.8748\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0221 - acc: 0.9837 - val_loss: 0.0950 - val_acc: 0.8747\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.0217 - acc: 0.9843 - val_loss: 0.0953 - val_acc: 0.8745\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0212 - acc: 0.9849 - val_loss: 0.0958 - val_acc: 0.8738\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.0208 - acc: 0.9853 - val_loss: 0.0962 - val_acc: 0.8729\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
    "\n",
    "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9714, 0.97253335, 0.9734667, 0.97386664, 0.9748667, 0.9764, 0.97653335, 0.9778, 0.9792, 0.98, 0.98, 0.9812, 0.9808667, 0.9818, 0.9827333, 0.9834, 0.98373336, 0.98433334, 0.9848667, 0.9853333]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다 (blue dot)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다 (solid blue line)\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# legend 는 아래에 나오는 범례\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_loss, val_accuracy, loss, accuracy --> val_loss, val_acc, loss, acc 로 업데이트 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
    "\n",
    "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
    "\n",
    "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 92us/step - loss: 0.4499 - accuracy: 0.8226\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 0.2586 - accuracy: 0.9100\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 0.1985 - accuracy: 0.9297\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 0.1657 - accuracy: 0.9414\n",
      "25000/25000 [==============================] - 2s 93us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2982311551475525, 0.8824399709701538]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16864476],\n",
       "       [0.9995246 ],\n",
       "       [0.6251841 ],\n",
       "       ...,\n",
       "       [0.09257215],\n",
       "       [0.05417174],\n",
       "       [0.6932545 ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
    "* 층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
    "* `binary_crossentropy` 대신에 `mse` 손실 함수를 사용해 보세요.\n",
    "* `relu` 대신에 `tanh` 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
    "\n",
    "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 89us/step - loss: 0.1324 - acc: 0.8223\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 0.0651 - acc: 0.9148\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 0.0503 - acc: 0.9344\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 0.0437 - acc: 0.9454\n",
      "25000/25000 [==============================] - 2s 90us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09858813894867897, 0.8728399872779846]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다:\n",
    "\n",
    "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
    "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
    "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
    "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
    "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
    "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
